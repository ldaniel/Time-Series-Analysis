---
title: "Exploração dos Modelos"
date: "Outubro de 2019"
---

```{r setup_evaluation, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos =  "h")
knitr::opts_knit$set(root.dir = "./")

# loading required libraries
library(dplyr)
library(zoo)
library(forecast)
library(lubridate)
library(readxl)
library(knitr)
```

```{r scripts_evaluation, include=FALSE}
# loading required steps before performing the analysis
source("../src/util/auxiliary_functions.R")
ClearEnvironment()
```

# Criando os datasets de séries temporais

Analisar séries temporais são úteis para verificar padrões e criar previsões de movimentos futuros. Baseado na base de dados alvo de nossa análise, iremos transformá-la em um dataset de série temporal e na sequência criar as bases de treino e teste.

## Carregando a base de dados processada

Carregamos a base de dados alvo, previamente tratada durante os passos explicados na fase de **Data Preparation** (preparação de dados).

A função **ts** vai converter um vetor de valores de uma base de dados em um objeto R de séries temporais. Devemos passar para a função a coluna alvo e os valores de data de início e fim do período de observação bem como sua frequência.

```{r data_load, echo=TRUE}
target_data <- readRDS('../data/processed/target_dataset.rds')

target_ts <- ts(target_data$Sales, 
                start = c(2005,1), 
                end = c(2010, 4), 
                frequency = 4)

summary(target_ts)
```

## Criando o conjunto de dados de treino e teste

Quando vamos criar um modelo de previsão de séries temporais o ideal é separar os dados em duas partes:

- **Treino:** estes dados serão a base principal para definir os coeficientes/parâmetros do modelo;
- **Teste:** são dados que serão separados e não foram vistos pelo modelo e serão usados para testá-lo e comparar com as previsões (geralmente comparando os valores passo-a-passo).

O tamanho do conjunto de testes é normalmente cerca de 20% da amostra total, embora esse percentual dependa do tamanho da amostra que você tenha e também quanto tempo adiante você deseja fazer a previsão. A base de testes deve ser idealmente pelo menos tão grande quanto o horizonte máximo de previsão necessário.

Diferente de outros métodos de previsões, como classificações e regressões sem a influência do tempo, em séries temporais não podemos dividir os dados de treino e teste com amostras aleatórias de qualquer parte dos dados, deve-se seguir o critério temporal da série, onde os dados de treino devem vir antes dos dados de teste.

```{r create_train_test_datasets, echo=TRUE, out.width='100%'}
# creating train and test sets ------------------------------------------------
GenerateTrainTestDatasets(target_ts,
                          c(2005, 1),
                          c(2009, 4),
                          c(2010, 1),
                          c(2010, 4))

train_ts <- readRDS('../data/processed/train_ts.rds')
test_ts  <- readRDS('../data/processed/test_ts.rds')
```

A seguir vemos o plot dos datasets de treino e teste.

```{r plot_train_test_datasets, echo=TRUE, out.width='100%'}
# plot of the training and testing temporal series
plot(train_ts, 
     xlab = "Tempo", 
     ylab = "Vendas", 
     xaxt = "n", 
     ylim = c(48000, 104000), 
     xlim = c(2005, 2011), 
     bty = "l")
axis(1, at = seq(2005, 2011, 1), labels = format(seq(2005, 2011, 1)))
lines(test_ts, bty = "l", col = "red")
box(lty = '1373', col = 'black')
```

*******************************************************************************

# Executado os modelos de análise de séries temporais

## Rodando e salvando os modelos lineares de séries temporais

Para executarmos todos os modelos lineares de séries temporais, utilizamos a função **GenerateLinearTimeSeriesModels** criada para rodar cada um dos modelos desejados, gravando os resultados no diretório do projeto **\\models** para uso futuro.

```
linear_consolidation <- GenerateLinearTimeSeriesModels(train_ts, test_ts)
```
```{r generating_linear_models, include=FALSE}
linear_consolidation <- GenerateLinearTimeSeriesModels(train_ts, test_ts)
```

Uma vez executada, a função retorna um preview com os resultados de MAPE para cada um dos modelos, mostrados a seguir.

```{r consolidated_linear_models_preview, echo=TRUE, out.width= '100%'}
kable(linear_consolidation)
```

## Rodando e salvando os modelos de suavização exponencial de séries temporais

Para executarmos todos os modelos de suavização exponencial de séries temporais, utilizamos a função **GenerateExponentialsmoothingStateTimeSeriesModel** criada para rodar cada um dos modelos desejados, gravando os resultados no diretório do projeto **\\models** para uso futuro.

```
smoothing_consolidation <- GenerateExponentialsmoothingStateTimeSeriesModel(target_ts, train_ts, test_ts)
```
```{r generating_smoothing_models, include=FALSE}
smoothing_consolidation <- GenerateExponentialsmoothingStateTimeSeriesModel(target_ts, train_ts, test_ts)
```

Uma vez executada, a função retorna um preview com os resultados de MAPE para cada um dos modelos, mostrados a seguir.

```{r consolidated_smoothing_models_preview, echo=TRUE, out.width='100%'}
kable(smoothing_consolidation)
```

*******************************************************************************

# Avaliando os modelos utilizados e seus resultados

Para análise inicial dos modelos será utilizado como base a métrica **MAPE** (Mean Absolute Percentage Error, ou Erro Percentual Médio Absoluto).

Essa métrica é interessante de ser usada, geralmente  em relatórios gerenciais, pois o erro é medido em termos percentuais e pode-se comparar o erro percentual do modelo de um produto X com o erro percentual de um produto Y.

O cálculo dessa métrica pega o valor absoluto do erro dividido pelo preço real e posteriormente é calculada a média:

$$MAPE = \frac{1}{n} \sum_{d_i} (\frac{1}{q} \sum_{t_j}\left\lvert{\frac{gap_{i,j}-s_{i,j}}{gap_{i,j}}}\right\rvert)$$

Para analisar o desempenho dos modelos utilizados em nosso dataset de série temporal, vamos primeiramente classificar do melhor para o pior, baseado no resultado de **MAPE**.

```{r checking_all_mape_results, echo=TRUE, out.width='100%'}
mape_ranking <- rbind(linear_consolidation, smoothing_consolidation) %>% 
        arrange(MAPE)
kable(mape_ranking)
```

O modelo de suavização exponencial **MMM** demonstrou a melhor métrica de **MAPE**, com o valor de **`r min(mape_ranking[,2])`**.

Para analisarmos com mais detalhes o modelo com melhor performance, vamos carregar o objeto salvo anteriormente com todos os resultados do modelo.

```{r loading_best_model, echo=TRUE, out.width='100%'}
best_model <- readRDS('../models/ts_exponential_smoothing_model_MMM.rds')
```

## Resultados gerais do modelo

```{r best_model_summary, echo=TRUE, out.width='100%'}
best_model$model
```

## Checando autocorrelação do modelo

```{r best_model_Acf, echo=TRUE, out.width='100%'}
best_model$Acf
```

## Checando resíduos do modelo

```{r best_model_residuals, echo=TRUE, out.width='100%'}
best_model$checkresiduals
```

## Checando a projeção do modelo

```{r best_model_projection, echo=TRUE, out.width='100%'}
best_model$model_projected
```

## Checando as métricas do modelo

```{r best_model_metrics, echo=TRUE, out.width='100%'}
best_model$model_projected_analisys
```

## Checando a projeção final do modelo

```{r best_model_final_projection, echo=TRUE, out.width='100%'}
best_model$model_final_projected
```
